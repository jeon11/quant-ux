{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jin Jeon\n",
    "\n",
    "HCDE 530 Computational Concepts\n",
    "\n",
    "## Project 2b: Google Cloud API and Textual Data Analysis\n",
    "\n",
    "### Introduction\n",
    "\n",
    "#### Using Google Cloud Platform and its API : \n",
    "**Google Cloud Platform** is a suite of cloud computing services that lets developers interact with APIs that involve data storage, data analytics, and machine learning. In this notebook, I use GoogleSheets API to directly read in sheets from the drive. Besides reading in the sheets, the API allows you to create, manipulate, filter, and organize metadata. \n",
    "\n",
    "With GoogleSheets API, I study survey data collected from my previous projects in user research. The process involves establishing credentials and keys so the program knows to use my credentials to access the private files. \n",
    "\n",
    "\n",
    "#### Goal of this notebook: \n",
    "\n",
    "Survey studies are essential for understanding the users because they can be quickly developed and sent out to receive a good amount of sample in a short period of time. Surveys are powerful to be utilized for conducting initial research at a discovery stage to explore the general problem space and user behaviors. \n",
    "\n",
    "One of the free and efficient tools is the Google Forms. With GoogleSheets API, we are able to access and manipulate incoming or completed data through code. Furthermore, we can easily shape and analyze data through Python. \n",
    "\n",
    "While Google Form is capable of generating pie graphs and bar graphs to summarize the survey results, the visualizations are often rudimentary or basic. Using Python, we can easily handle large sets of data and breakdown and analyze the data by each demographic group, and probe for any interesting results.\n",
    "\n",
    "**Specifically, let's see if there are any significant differences or responses that are made for each age group and gender.**\n",
    "\n",
    "** _**Disclaimer:** Some of the code is an extension from my previous assignment._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Sentiment Analysis using Google Natural Language API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "import os\n",
    "from google.cloud import language_v1\n",
    "\n",
    "# set environment for credentials (need to be called with every start of instance)\n",
    "# refer the reference tab for setting credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/Jin/google-cloud-sdk/natural-language-api.json\"\n",
    "\n",
    "# Instantiates a client\n",
    "client = language_v1.LanguageServiceClient()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Short summary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        string of text to be analyzed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prints out sentiment score (-1, 1) and magnitude\n",
    "    \"\"\"\n",
    "    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detects the sentiment of the text\n",
    "    sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment\n",
    "\n",
    "    print(\"Text: {}\".format(text))\n",
    "    print(\"Sentiment: {}, {}\".format(sentiment.score, sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick glimpse at the sentiment analysis\n",
    "Let's try feeding in some random sentences and see how sentiments turn out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The dish was delightfully delicious.\n",
      "Sentiment: 0.8999999761581421, 0.8999999761581421\n",
      "Text: The overall experience was terrible.\n",
      "Sentiment: -0.800000011920929, 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# The text to analyze\n",
    "text = u\"The dish was delightfully delicious.\"\n",
    "text2 = u\"The overall experience was terrible.\"\n",
    "\n",
    "analyze_sentiment(text)\n",
    "\n",
    "analyze_sentiment(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Google Sheets API\n",
    "\n",
    "The high level process of setting up Google API is as follows: \n",
    "\n",
    "**1. Create an Oauth credential** (Instruction link: https://developers.google.com/workspace/guides/create-credentials)\n",
    "\n",
    "\n",
    "**2. Pip install the required packages** \n",
    "\n",
    "> ` pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib` \n",
    "\n",
    "**3. Set scope and spreadsheet ID**\n",
    "\n",
    " - **Auth scopes** set the permissions that your code requests to authorize for the app\n",
    "For example, scope code of:\n",
    "    - **.readonly** allows to read all resources and the meta data but with no writing operations\n",
    "    - **.label** lets you create, read, update, and delete labels. \n",
    "\n",
    "- **Spreadsheet ID** is the parameter that gets used to tell which spreadsheet to access. The ID is called from a part of the full URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation\n",
    "\n",
    "Please note that the following code will only run if you have your Google `credential.json` and `token.json` within the working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'token.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f1b48b1131dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mRANGE_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'health_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_authorized_user_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCOPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sheets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.6/site-packages/google/oauth2/credentials.py\u001b[0m in \u001b[0;36mfrom_authorized_user_file\u001b[0;34m(cls, filename, scopes)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_authorized_user_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'token.json'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "SPREADSHEET_ID = '11Den6g5nuR4B2CCUML1KrA0bEZXRpPZ7t83Ieyi7NJ4'\n",
    "\n",
    "# Specify which sheet or row/column of data to call in\n",
    "# refer to https://developers.google.com/sheets/api/guides/concepts#a1_notation for detail\n",
    "RANGE_NAME = 'health_data'\n",
    "\n",
    "creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "# Call the Sheets API to read in the data\n",
    "sheet = service.spreadsheets()\n",
    "result = sheet.values().get(spreadsheetId = SPREADSHEET_ID,\n",
    "                            range = RANGE_NAME).execute()\n",
    "values = result.get('values', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have the sheet successfully loaded without having to open the Google Drive at all. We can use the data on the fly. Below, we will just confirm the data type that the data was read in.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "print(type(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's convert it into a pandas dataframe so we can easily manipuate the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(values[1:], columns=values[0])\n",
    "\n",
    "# let's confirm \n",
    "print(type(data))\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "From the code above, we translated the data into pandas dataframe. Using `data.shape`, we know that there are total 27 questions collected from 71 participants. For simplicity, I remove any data that does not prefer to disclose gender. This brings the data size to 68. Due to the extensive length and branching logic within the survey, the data becomes more textual and qualitative for questions or columns in the back. I will primarily use selected columns that are of interest. \n",
    "\n",
    "Let's have a quick glance at the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity, let's constrain the gender option to only two\n",
    "gender_options = ['Man', 'Woman']\n",
    "data = data[data['What is your gender?'].isin(gender_options)]\n",
    "\n",
    "print('There are total ' + str(len(data)) + ' participants.')\n",
    "print('The survey consists of ' + str(data.shape[1]) + ' questions (columns in the dataframe).')\n",
    "\n",
    "# convert the column string values to integers\n",
    "data['How would you rate your health?'] = data['How would you rate your health?'].astype(int)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Now that we have seen the general dataframe structure, let's explore probing the data for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import scipy\n",
    "from tabulate import tabulate\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)  # suppress any warning\n",
    "sns.set_color_codes('pastel')  # set color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying data\n",
    "Before we play around with data, let's query out the data that are of interest. This way we can manipulate the data more effectively without having to call on the entire dataset `data` everytime. \n",
    "\n",
    "There are total 7 different age groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's divde the data by gender first \n",
    "females = data.loc[data['What is your gender?'] == 'Woman']\n",
    "males = data.loc[data['What is your gender?'] == 'Man']\n",
    "\n",
    "# let's also create dataset divided by age group\n",
    "age_under18 = data.loc[data['What age range are you?'] == 'Under 18']\n",
    "age_18to24 = data.loc[data['What age range are you?'] == '18 - 24']\n",
    "age_25to34 = data.loc[data['What age range are you?'] == '25 - 34']\n",
    "age_35to44 = data.loc[data['What age range are you?'] == '35 - 44']\n",
    "age_45to54 = data.loc[data['What age range are you?'] == '45 - 54']\n",
    "age_55to64 = data.loc[data['What age range are you?'] == '55 - 64']\n",
    "age_over65 = data.loc[data['What age range are you?'] == '65 or older']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(males))\n",
    "print(len(females))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question: How does self-perception of health rating differ by gender and age?\n",
    "\n",
    "Participants were asked, How would you rate your health? (5 being healthy, 1 being not healthy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Health rating by gender\n",
    "Let's breakdown the data to see how self-perception of health wellness varies by gender and different age groups. In the code below, I first quary females and males from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns[4] is the column for health rating\n",
    "mean_males = np.mean(males[males.columns[4]])\n",
    "mean_females = np.mean(females[females.columns[4]])\n",
    "\n",
    "print(\"Mean of males' self-health wellness: \" + str(mean_males))\n",
    "print(\"Mean of females' self-health wellness: \" + str(mean_females))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Health rating by age group\n",
    "\n",
    "Now let's breakdown the data to see how self-perception of health wellness varies by different age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = data.groupby('What age range are you?')['How would you rate your health?'].mean()\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversely, the age group 65 or older actually has the highest self-perception of wellness. The youngest group (age under 18) rated the lowest.**\n",
    "\n",
    "### C. T-test for statistical signifcance\n",
    "**However, with small samples of the two demographic groups `65 or older` and `Under 18`, we are not sure if the difference we see here is significant. Let's run a quick t-test to see if the difference we are seeing is statistically significant.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = scipy.stats.ttest_ind(age_over65['How would you rate your health?'], age_under18['How would you rate your health?'])\n",
    "\n",
    "print('t: ' + str(t.round(4)))  \n",
    "print('p: ' + str(p.round(4)))  # the p-val should be less than 0.05 in general to assume the difference we observe is signifcant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the p-value is 0.01 which is signifcant, which is one interesting find! So we can say that within this dataset, the people age over 65 perceive themselves to be more healthy than teenagers would do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Health rating by age & gender group\n",
    "\n",
    "Now let's breakdown by both gender and different age groups to look at how the self perception of health wellness change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender = data.groupby(['What age range are you?', 'What is your gender?'])['How would you rate your health?'].mean().round(2)\n",
    "\n",
    "age_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Iteratively running t-test within each age group\n",
    "We have several different age groups with each male and female gender group. Within each age group, let's run a t-test to see if there are any significant observed differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_options = ['Man', 'Woman']\n",
    "age_groups = ['age_under18', 'age_18to24', 'age_25to34', 'age_35to44', 'age_45to54', 'age_55to64', 'age_over65']\n",
    "\n",
    "table = []\n",
    "table.append(['age group', 't value', 'p value'])\n",
    "\n",
    "# iteratively run for t-tests within each age group defined in the list variable 'age_groups'\n",
    "for i in range(0, len(age_groups)):\n",
    "    data_string = \"['How would you rate your health?']\"\n",
    "    eval_string1 = age_groups[i] + '.loc[' + age_groups[i] + \"['What is your gender?'] == 'Man']\"\n",
    "    a = eval(eval_string1 + data_string)\n",
    "    eval_string2 = age_groups[i] + '.loc[' + age_groups[i] + \"['What is your gender?'] == 'Woman']\"\n",
    "    b = eval(eval_string2 + data_string)\n",
    "#     strings_combined = 'scipy.stats.ttest_ind(a, b)'\n",
    "\n",
    "    t, p = eval('scipy.stats.ttest_ind(a, b)')\n",
    "    \n",
    "    # we use a package called tabulate to print out a formatted table\n",
    "    table.append([age_groups[i], t.round(4) ,p.round(4)])\n",
    "\n",
    "print(tabulate(table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see that the p-values are all above 0.05 which means that there are no observed significant differences in gender within each age group.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Let's first try plotting a simple visual violin plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_plot = sns.catplot(x='What age range are you?', y='How would you rate your health?', \\\n",
    "                       hue='What is your gender?', kind=\"violin\", data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterizing textual data through wordcloud\n",
    "Let's change focus and try analyzing textual inputs from the participants. We will analyze the column How is your health and/or fitness information being used? question to identify any emerging keywords using the word cloud representation. Disclaimer: The result here is not such a useful or accurate representation as the stopwords did not clearly filter out.\n",
    "\n",
    "We first call in a list of stopwords to filter out any unnecessary words, such as 'I', 'and', and etc. We then flatten out all the responses into a single list of words.\n",
    "\n",
    "### Is there gender difference in how they use health data (text responses)? \n",
    "\n",
    "Participants were asked, \"How is your health and/or fitness information being used?\" Here, I try to breakdown the text data through representation of wordcloud, and see if there any characteristics found in each gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin stopword sets from nltk \n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def plot_wordcloud(df, col, separator=None): \n",
    "    \"\"\"\n",
    "    Plots a wordcloud of given dataframe and specific column. The text is counted at word level.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "        dataframe that contains textual data\n",
    "    col: int\n",
    "        integer that points to the specific column with textual data \n",
    "    separator: str (default: None)\n",
    "        string specified to breakdown the text by. Default is empty space\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    Wordcloud plot \n",
    "    \n",
    "    list of most common words in the dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    # filter out any NaNs\n",
    "    response = [x for x in df[df.columns[col]] if x == x]\n",
    "    # filter out any None\n",
    "    response = [x for x in response if x != None]\n",
    "\n",
    "    word_dict = []\n",
    "    for i in range(0, len(response)):\n",
    "        if separator == None:\n",
    "            word_dict.append(response[i].split())\n",
    "        else: \n",
    "            word_dict.append(response[i].split(separator))\n",
    "    word_filtered = []\n",
    "\n",
    "    # flatten the list and lower all letter cases\n",
    "    for sublist in word_dict:\n",
    "        for item in sublist:\n",
    "            word_filtered.append(item.lower())\n",
    "\n",
    "    # remove stopwords\n",
    "    word_filtered = [x for x in word_filtered if x not in stop]\n",
    "\n",
    "    word_filtered = [word.replace('.','').replace(',', '').replace(\"'\",'') for word in word_filtered]\n",
    "    \n",
    "    # print most common words\n",
    "    most_common_words = Counter(word_filtered).most_common(10)\n",
    "    print(most_common_words)\n",
    "    \n",
    "    # plot wordcloud\n",
    "    texts = \" \".join(word for word in word_filtered)\n",
    "    cloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(texts)\n",
    "    plt.imshow(cloud, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wordcloud for Man\n",
    "plot_wordcloud(males, 24)  # 24 specifies the column number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wordcloud for Woman\n",
    "plot_wordcloud(females, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top image is the wordcloud of male participants and the bottom is that of female participants. We see that some words are not as meaningful and that one critical fault to this approach is that breaking down the responses into word level can misrepresent the meaning of their responses. For example, 'exercise' and 'not exercise' have two opposing ideas but here, it would count 'not' and 'exercise' as two seperate ideas. \n",
    "\n",
    "Even though the word counts are small, we see more 'food' and 'sleep' for female participants, leading to an assumption that it could be related to going on diets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing categorical data using wordcloud\n",
    "\n",
    "Participants were also asked, \"what actions do you take regarding your health?\" with multiple choices answer selections that include...\n",
    "1. 'exercise'\n",
    "2. 'take medication or health supplements'\n",
    "3. 'track health or fitness'\n",
    "4. 'learn more about health'\n",
    "5. 'receive regular treatment at clinic'\n",
    "6. 'maintain a diet'\n",
    "7. 'receive mental counseling.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(males, 3, ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(females, 3, ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the two results above, we see that exercise is the most common practice for keeping up health in both genders. However, we see that in general, women tend to do more activities or attempts to maintain their health e.g. more frequently visits the clinic or receive counseling, whereas two men responded they simply do nothing at all.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Thoughts\n",
    "Wordcloud is a fun, engaging representation of textual data. However, more caution and consideration are needed because it can also tweak how the data is represented. For example, I coded the function so that it would breakdown any sentences or phrases into word level. This means that if someone does 'not exercise', it would still count 'exercise' and the end result would show 'exercise' being emphasized more. While the context of exercise is present, the meaning is totally the opposite.\n",
    "\n",
    "### Future work\n",
    "As much as I am interested in exploring textual data, I want to explore sentiment analysis and NLP models that could facilitate the analysis step of textual data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "GoogleSheets API v4: https://developers.google.com/sheets/api/samples/reading\n",
    "\n",
    "Google Oauth: https://developers.google.com/identity/protocols/oauth2/service-account#python\n",
    "\n",
    "Google API Python Client: https://github.com/googleapis/google-api-python-client/blob/master/docs/oauth.md\n",
    "\n",
    "Credentials: https://developers.google.com/workspace/guides/create-credentials\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
